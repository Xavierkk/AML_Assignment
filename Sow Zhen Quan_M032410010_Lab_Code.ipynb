{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baad6008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"diabetes_result.csv\")\n",
    "\n",
    "# Display basic information and the first few rows\n",
    "df.info()\n",
    "df.describe()\n",
    "\n",
    "\n",
    "# Rows: 768\n",
    "# Target Variable: Outcome (1 = Diabetic, 0 = Non-Diabetic)\n",
    "# Features: Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age\n",
    "# Issue Detected: The Insulin, SkinThickness, and possibly Glucose and BloodPressure columns contain 0 values which may represent missing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cacc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Exclude non-numeric columns like 'id' if present\n",
    "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "if 'id' in numeric_cols:\n",
    "    numeric_cols = numeric_cols.drop('id')\n",
    "\n",
    "# Plot histograms for all numeric features\n",
    "n_cols = 3\n",
    "n_rows = (len(numeric_cols) + n_cols - 1) // n_cols\n",
    "\n",
    "plt.figure(figsize=(18, 5 * n_rows))\n",
    "for i, col in enumerate(numeric_cols, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    plt.hist(df[col], bins=20, edgecolor='black', color='skyblue')\n",
    "    plt.title(f\"{col} Distribution\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e350c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing value\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make a copy\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Columns to exclude from 0 ‚Üí NaN replacement\n",
    "exclude_cols = ['Outcome', 'id'] if 'id' in df.columns else ['Outcome']\n",
    "\n",
    "# Replace 0 with NaN in relevant features\n",
    "cols_to_check = df_cleaned.columns.difference(exclude_cols)\n",
    "df_cleaned[cols_to_check] = df_cleaned[cols_to_check].replace(0, np.nan)\n",
    "\n",
    "# Count of missing values\n",
    "missing_counts = df_cleaned.isnull().sum()\n",
    "\n",
    "# Percentage of missing values\n",
    "missing_percentage = (missing_counts / len(df_cleaned)) * 100\n",
    "\n",
    "# Combine into one table\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Count': missing_counts,\n",
    "    'Missing Percentage (%)': missing_percentage.round(2)\n",
    "})\n",
    "\n",
    "# Display the table\n",
    "print(\"üîç Missing Values Summary:\")\n",
    "print(missing_summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e3524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing value\n",
    "\n",
    "##############################\n",
    "# The dataset has no missing values (Non-Null Count = 768 for all columns)\n",
    "# However, biologically implausible values like 0 in Glucose, BloodPressure, SkinThickness, Insulin, and BMI may indicate missing data.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset (only if not already loaded)\n",
    "# df = pd.read_csv(\"diabetes_result.csv\")\n",
    "\n",
    "# Make a copy\n",
    "df_cleaned = df.copy()\n",
    "\n",
    "# Define columns with biologically implausible zero values (to be treated as missing)\n",
    "cols_with_invalid_zeros = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "\n",
    "# Replace 0 with NaN only in those columns (not in Pregnancies)\n",
    "df_cleaned[cols_with_invalid_zeros] = df_cleaned[cols_with_invalid_zeros].replace(0, np.nan)\n",
    "\n",
    "# Count missing values before imputation\n",
    "missing_before = df_cleaned[cols_with_invalid_zeros].isnull().sum()\n",
    "\n",
    "# Prepare data for imputation ‚Äî exclude 'id' and 'Outcome'\n",
    "features_only = df_cleaned.drop(columns=['id', 'Outcome'])\n",
    "\n",
    "# Standardize features for KNN\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features_only)\n",
    "\n",
    "# Apply KNN Imputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "features_imputed = imputer.fit_transform(features_scaled)\n",
    "\n",
    "# Inverse transform to return to original scale\n",
    "features_unscaled = scaler.inverse_transform(features_imputed)\n",
    "features_clean = pd.DataFrame(features_unscaled, columns=features_only.columns)\n",
    "\n",
    "# Combine with 'id' and 'Outcome'\n",
    "df_imputed_final = pd.concat([df_cleaned[['id', 'Outcome']].reset_index(drop=True), features_clean], axis=1)\n",
    "\n",
    "# Recheck missing values after imputation\n",
    "missing_after = df_imputed_final[cols_with_invalid_zeros].isnull().sum()\n",
    "\n",
    "# Summary stats before and after imputation\n",
    "summary_before = df[cols_with_invalid_zeros].describe()\n",
    "summary_after = df_imputed_final[cols_with_invalid_zeros].describe()\n",
    "\n",
    "# Create a comparison DataFrame for missing values\n",
    "missing_summary = pd.DataFrame({\n",
    "    \"Missing Before Imputation\": missing_before,\n",
    "    \"Missing After Imputation\": missing_after\n",
    "})\n",
    "print(\"Missing Value Summary:\")\n",
    "print(missing_summary)\n",
    "\n",
    "print(\"\\nSummary Statistics Before Imputation:\")\n",
    "print(summary_before)\n",
    "\n",
    "print(\"\\nSummary Statistics After Imputation:\")\n",
    "print(summary_after)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df, df_cleaned, and df_imputed_final are loaded and processed as per the script\n",
    "\n",
    "# Extract relevant feature columns excluding 'id' and 'Outcome'\n",
    "features_to_plot = df.columns.difference(['id', 'Outcome'])\n",
    "\n",
    "# Set up plot layout\n",
    "n_features = len(features_to_plot)\n",
    "n_cols = 3\n",
    "n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "plt.figure(figsize=(18, 5 * n_rows))\n",
    "\n",
    "# Plot histograms before and after imputation\n",
    "for i, feature in enumerate(features_to_plot, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    plt.hist(df[feature].dropna(), bins=20, alpha=0.5, label='Before', color='orange', edgecolor='black')\n",
    "    plt.hist(df_imputed_final[feature], bins=20, alpha=0.5, label='After', color='green', edgecolor='black')\n",
    "    plt.title(f\"{feature} Distribution\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78695f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Handling with median\n",
    "\n",
    "########################################\n",
    "# Outlier handling on the KNN-imputed data (df_imputed_final)\n",
    "# Exclude 'id', 'Outcome', and 'Age' from processing\n",
    "def handle_outliers_iqr(df, exclude_cols=None):\n",
    "    df_out = df.copy()\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col in exclude_cols:\n",
    "            continue\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        median = df[col].median()\n",
    "        outliers = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "        df_out.loc[outliers, col] = median\n",
    "    return df_out\n",
    "\n",
    "# Apply IQR-based outlier handling\n",
    "df_outliers_handled = handle_outliers_iqr(df_imputed_final, exclude_cols=['id', 'Outcome', 'Age'])\n",
    "\n",
    "# Compare summaries before and after outlier handling (excluding 'id' and 'Outcome')\n",
    "summary_before_outliers = df_imputed_final.drop(columns=['id', 'Outcome']).describe()\n",
    "summary_after_outliers = df_outliers_handled.drop(columns=['id', 'Outcome']).describe()\n",
    "\n",
    "print(\"\\nSummary Statistics Before Outlier Handling:\")\n",
    "print(summary_before_outliers)\n",
    "\n",
    "print(\"\\nSummary Statistics After Outlier Handling:\")\n",
    "print(summary_after_outliers)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Features to plot (excluding ID and Outcome)\n",
    "features_to_plot = df_imputed_final.columns.difference(['id', 'Outcome'])\n",
    "\n",
    "# Set up plot layout\n",
    "n_features = len(features_to_plot)\n",
    "n_cols = 3\n",
    "n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "plt.figure(figsize=(18, 5 * n_rows))\n",
    "\n",
    "# Plot histograms before and after outlier handling\n",
    "for i, feature in enumerate(features_to_plot, 1):\n",
    "    plt.subplot(n_rows, n_cols, i)\n",
    "    plt.hist(df_imputed_final[feature], bins=20, alpha=0.5, label='Before', color='orange', edgecolor='black')\n",
    "    plt.hist(df_outliers_handled[feature], bins=20, alpha=0.5, label='After', color='green', edgecolor='black')\n",
    "    plt.title(f\"{feature} Distribution\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578c041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "\n",
    "#####################################\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Round pregnancies to keep it discrete before EDA\n",
    "df_eda_ready = df_outliers_handled.copy()\n",
    "df_eda_ready['Pregnancies'] = df_eda_ready['Pregnancies'].round().astype(int)\n",
    "\n",
    "# Distribution plots\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.countplot(data=df_eda_ready, x='Outcome')\n",
    "plt.title(\"Class Distribution: Diabetes Outcome\")\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation_matrix = df_eda_ready.drop(columns=['id']).corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n",
    "\n",
    "# Pairplot (sample)\n",
    "sns.pairplot(df_eda_ready.drop(columns='id'), hue='Outcome', corner=True)\n",
    "plt.suptitle(\"Pairwise Feature Relationships\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Boxplots for each feature by Outcome\n",
    "features = df_eda_ready.columns.drop(['id', 'Outcome'])\n",
    "plt.figure(figsize=(20, 25))\n",
    "for i, col in enumerate(features):\n",
    "    plt.subplot(5, 2, i+1)\n",
    "    sns.boxplot(data=df_eda_ready, x='Outcome', y=col)\n",
    "    plt.title(f\"{col} by Diabetes Outcome\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47adbab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "import pandas as pd\n",
    "\n",
    "# Prepare\n",
    "features = df_eda_ready.columns.drop(['id', 'Outcome'])\n",
    "group0 = df_eda_ready[df_eda_ready['Outcome'] == 0]\n",
    "group1 = df_eda_ready[df_eda_ready['Outcome'] == 1]\n",
    "\n",
    "# Run ANOVA per feature\n",
    "results = []\n",
    "\n",
    "for feature in features:\n",
    "    stat, p = f_oneway(group0[feature], group1[feature])\n",
    "    significance = ''\n",
    "    if p < 0.001:\n",
    "        significance = '***'  # Highly significant\n",
    "    elif p < 0.01:\n",
    "        significance = '**'   # Very significant\n",
    "    elif p < 0.05:\n",
    "        significance = '*'    # Significant\n",
    "    else:\n",
    "        significance = 'ns'   # Not significant\n",
    "    \n",
    "    results.append({\n",
    "        'Feature': feature,\n",
    "        'F-Statistic': round(stat, 3),\n",
    "        'p-Value': round(p, 6),\n",
    "        'Significance': significance\n",
    "    })\n",
    "\n",
    "# Create and print table\n",
    "anova_df = pd.DataFrame(results)\n",
    "#anova_df = anova_df.sort_values(by='p-Value')\n",
    "anova_df = anova_df.sort_values(by=['p-Value', 'F-Statistic'], ascending=[True, False])\n",
    "\n",
    "\n",
    "# Display as a clean text table\n",
    "print(\"=== Feature-wise ANOVA Results ===\")\n",
    "print(anova_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dc8042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "X = df_eda_ready.drop(columns=['id', 'Outcome'])\n",
    "X = add_constant(X)  # Add constant for VIF calculation\n",
    "\n",
    "vif_df = pd.DataFrame()\n",
    "vif_df[\"Feature\"] = X.columns\n",
    "vif_df[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(vif_df.sort_values(by='VIF', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955981d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering (intraction + categorization + log transform)\n",
    "\n",
    "############################################################\n",
    "\n",
    "df = df_outliers_handled.copy()  # <-- Start from clean data\n",
    "\n",
    "# Interaction features\n",
    "df['Glucose_Insulin'] = df['Glucose'] * df['Insulin']\n",
    "df['Glucose_BMI'] = df['Glucose'] * df['BMI']\n",
    "df['Insulin_BMI'] = df['Insulin'] * df['BMI']\n",
    "\n",
    "# Discretization (binning) into categories\n",
    "df['Glucose_Bin'] = pd.cut(df['Glucose'], bins=[0, 90, 125, 150, 200], labels=[0, 1, 2, 3])\n",
    "df['BMI_Bin'] = pd.cut(df['BMI'], bins=[0, 25, 30, 35, 50], labels=[0, 1, 2, 3])\n",
    "df['Age_Bin'] = pd.cut(df['Age'], bins=[20, 30, 40, 50, 70, 90], labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adc1763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram plot before log transformation\n",
    "\n",
    "###################################################################\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a list of features to visualize (you can adjust this as needed)\n",
    "features_to_plot = [\n",
    "    'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "    'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome',\n",
    "    'Glucose_Insulin', 'Glucose_BMI', 'Insulin_BMI',\n",
    "    'Glucose_Bin', 'BMI_Bin', 'Age_Bin'\n",
    "]\n",
    "\n",
    "# Setup figure size and layout\n",
    "num_features = len(features_to_plot)\n",
    "cols = 4\n",
    "rows = (num_features // cols) + int(num_features % cols > 0)\n",
    "\n",
    "plt.figure(figsize=(20, 5 * rows))\n",
    "\n",
    "# Plot each histogram\n",
    "for i, feature in enumerate(features_to_plot, 1):\n",
    "    plt.subplot(rows, cols, i)\n",
    "    \n",
    "    # Handle categorical bin plots\n",
    "    if str(df[feature].dtype) == 'category':\n",
    "        sns.histplot(df[feature].cat.codes, bins=len(df[feature].cat.categories), color='skyblue')\n",
    "    else:\n",
    "        sns.histplot(df[feature], bins=30, kde=False, color='steelblue')\n",
    "    \n",
    "    plt.title(f'{feature}')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8284b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log Transformation\n",
    "\n",
    "###################################\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# -------------------------------\n",
    "# Log-transform skewed features\n",
    "df['Log_Insulin'] = np.log1p(df['Insulin'])  # log1p = log(x + 1)\n",
    "df['Log_DPF'] = np.log1p(df['DiabetesPedigreeFunction'])\n",
    "df['Log_Age'] = np.log1p(df['Age'])\n",
    "df['Log_Glucose_Insulin'] = np.log1p(df['Glucose_Insulin'])\n",
    "df['Log_Insulin_BMI'] = np.log1p(df['Insulin_BMI'])\n",
    "\n",
    "# -------------------------------\n",
    "# List of features to visualize\n",
    "features_to_plot = [\n",
    "    'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
    "    'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome',\n",
    "    'Glucose_Insulin', 'Glucose_BMI', 'Insulin_BMI',\n",
    "    'Log_Insulin', 'Log_DPF', 'Log_Age','Log_Glucose_Insulin', 'Log_Insulin_BMI',\n",
    "    'Glucose_Bin', 'BMI_Bin', 'Age_Bin'\n",
    "]\n",
    "\n",
    "# -------------------------------\n",
    "# Setup figure size and layout\n",
    "num_features = len(features_to_plot)\n",
    "cols = 4\n",
    "rows = (num_features // cols) + int(num_features % cols > 0)\n",
    "\n",
    "plt.figure(figsize=(22, 5 * rows))\n",
    "\n",
    "# Plot histograms\n",
    "for i, feature in enumerate(features_to_plot, 1):\n",
    "    plt.subplot(rows, cols, i)\n",
    "    \n",
    "    # Plot categorical bins using .cat.codes\n",
    "    if str(df[feature].dtype) == 'category':\n",
    "        sns.histplot(df[feature].cat.codes, bins=len(df[feature].cat.categories), color='skyblue')\n",
    "    else:\n",
    "        sns.histplot(df[feature], bins=30, kde=False, color='steelblue')\n",
    "    \n",
    "    plt.title(f'{feature}')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81757760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "import pandas as pd\n",
    "\n",
    "# Split data into Outcome groups\n",
    "group0 = df[df['Outcome'] == 0]\n",
    "group1 = df[df['Outcome'] == 1]\n",
    "\n",
    "# Drop 'Outcome' and 'id', select numeric features\n",
    "features_to_test = df.select_dtypes(include='number').drop(columns=['Outcome', 'id'], errors='ignore').columns\n",
    "\n",
    "# Run ANOVA\n",
    "anova_results = []\n",
    "\n",
    "for feature in features_to_test:\n",
    "    stat, p = f_oneway(group0[feature], group1[feature])\n",
    "    \n",
    "    if p < 0.001:\n",
    "        sig = '***'\n",
    "    elif p < 0.01:\n",
    "        sig = '**'\n",
    "    elif p < 0.05:\n",
    "        sig = '*'\n",
    "    else:\n",
    "        sig = 'ns'\n",
    "    \n",
    "    anova_results.append({\n",
    "        'Feature': feature,\n",
    "        'F-Statistic': round(stat, 3),\n",
    "        'p-Value': round(p, 6),\n",
    "        'Significance': sig\n",
    "    })\n",
    "\n",
    "# Sort by F-statistic descending\n",
    "anova_df = pd.DataFrame(anova_results).sort_values(by='F-Statistic', ascending=False)\n",
    "\n",
    "# Display\n",
    "print(\"=== ANOVA Test Results (Sorted by Significance) ===\")\n",
    "print(anova_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6de505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "\n",
    "####################################################\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = df.drop(columns=['id'])\n",
    "\n",
    "# Define features to standardize (drop Outcome, ID, and bins)\n",
    "features_to_standardize = [\n",
    "    'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI',\n",
    "    'DiabetesPedigreeFunction', 'Age', 'Glucose_Insulin', 'Glucose_BMI', 'Insulin_BMI',\n",
    "    'Log_Insulin', 'Log_DPF', 'Log_Age', 'Log_Glucose_Insulin', 'Log_Insulin_BMI'\n",
    "]\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform\n",
    "df_standardized = df.copy()\n",
    "df_standardized[features_to_standardize] = scaler.fit_transform(df_standardized[features_to_standardize])\n",
    "\n",
    "# Now df_standardized has scaled features\n",
    "\n",
    "df_standardized.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b44e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = features, drop Outcome and ID/bins\n",
    "X = df_standardized.drop(columns=['Outcome', 'Glucose_Bin', 'BMI_Bin', 'Age_Bin'])\n",
    "\n",
    "# y = target\n",
    "y = df_standardized['Outcome']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split before any feature selection\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb39c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest model\n",
    "\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "    from sklearn.metrics import (\n",
    "        accuracy_score, precision_score, recall_score, f1_score,\n",
    "        roc_auc_score, roc_curve, precision_recall_curve,\n",
    "        confusion_matrix, ConfusionMatrixDisplay\n",
    "    )\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # Prepare dataset (assumes df is preloaded)\n",
    "    df = df.drop(columns='id', errors='ignore')\n",
    "    X_full = df.drop(columns=['Outcome', 'Glucose_Bin', 'BMI_Bin', 'Age_Bin'], errors='ignore')\n",
    "    y = df['Outcome']\n",
    "\n",
    "    # Step 0: Feature Importance Selection using Random Forest\n",
    "    rf_initial = RandomForestClassifier(random_state=42)\n",
    "    rf_initial.fit(X_full, y)\n",
    "\n",
    "    feature_importances = pd.Series(rf_initial.feature_importances_, index=X_full.columns)\n",
    "    selected_features = feature_importances.sort_values(ascending=False).head(10).index.tolist()\n",
    "\n",
    "    print(\"=== Selected Top 10 Features by Random Forest ===\")\n",
    "    print(selected_features)\n",
    "\n",
    "    X = X_full[selected_features]\n",
    "\n",
    "    # Step 1: Train-test split (stratified)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    # Step 2: SMOTE to balance training data\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Step 3: Hyperparameter tuning for Random Forest\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [4, 6, 8],\n",
    "        'min_samples_split': [4, 6, 8],\n",
    "        'min_samples_leaf': [2, 4, 6],\n",
    "        'max_features': ['sqrt', 0.5]\n",
    "    }\n",
    "\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_search = RandomizedSearchCV(\n",
    "        rf_model, param_distributions=param_grid,\n",
    "        n_iter=25, scoring='f1', cv=15, n_jobs=-1, verbose=0, random_state=42\n",
    "    )\n",
    "    rf_search.fit(X_train_res, y_train_res)\n",
    "    best_rf = rf_search.best_estimator_\n",
    "\n",
    "    # Displaying the best parameters found by RandomizedSearchCV\n",
    "    best_parameters = rf_search.best_params_\n",
    "    print(\"=== Best Hyperparameters Found ===\")\n",
    "    print(best_parameters)\n",
    "\n",
    "    # Step 4: Evaluation\n",
    "    results = {}\n",
    "    y_pred_train = best_rf.predict(X_train_res)\n",
    "    y_pred_test = best_rf.predict(X_test)\n",
    "    y_proba_train = best_rf.predict_proba(X_train_res)[:, 1]\n",
    "    y_proba_test = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    for label, y_data, y_pred, y_proba in [\n",
    "        ('Train', y_train_res, y_pred_train, y_proba_train),\n",
    "        ('Test', y_test, y_pred_test, y_proba_test)\n",
    "    ]:\n",
    "        results[label] = {\n",
    "            'Accuracy': accuracy_score(y_data, y_pred),\n",
    "            'Precision': precision_score(y_data, y_pred),\n",
    "            'Recall': recall_score(y_data, y_pred),\n",
    "            'F1 Score': f1_score(y_data, y_pred),\n",
    "            'Average Recall': (recall_score(y_data, y_pred, pos_label=1) + recall_score(y_data, y_pred, pos_label=0)) / 2,\n",
    "            'AUC': roc_auc_score(y_data, y_proba),\n",
    "            'FPR_TPR': roc_curve(y_data, y_proba)\n",
    "        }\n",
    "\n",
    "    # === Plotting ===\n",
    "    # ROC Curves\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    for ax, (label, res) in zip(axes, results.items()):\n",
    "        fpr, tpr, _ = res['FPR_TPR']\n",
    "        ax.plot(fpr, tpr, label=f'Random Forest ({label} AUC = {res[\"AUC\"]:.2f})')\n",
    "        ax.plot([0, 1], [0, 1], linestyle='--', color='orange')\n",
    "        ax.set_title(f'Random Forest ROC Curve ({label} Set)')\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # === Confusion Matrices ===\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    for ax, (label, y_true, y_pred) in zip(axes, [\n",
    "        ('Train', y_train_res, y_pred_train),\n",
    "        ('Test', y_test, y_pred_test)\n",
    "    ]):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "        disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
    "        ax.set_title(f'Random Forest Confusion Matrix ({label} Set)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # === Results Summary ===\n",
    "    results_summary = pd.DataFrame(results).T.drop(columns='FPR_TPR').round(3)\n",
    "\n",
    "    print(\"=== Train vs Test Performance ===\")\n",
    "    print(results_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0b82e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest model with categorical features\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve,\n",
    "    confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.calibration import calibration_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume df is already loaded and cleaned\n",
    "\n",
    "# Include categorical bin features into feature set\n",
    "categorical_features = ['Glucose_Bin', 'BMI_Bin', 'Age_Bin']\n",
    "\n",
    "# Make sure categorical features are integers\n",
    "for cat in categorical_features:\n",
    "    df[cat] = df[cat].astype(int)\n",
    "\n",
    "# Step 0: Full feature set including numerical + categorical\n",
    "X_full = df.drop(columns=['Outcome'], errors='ignore')\n",
    "y = df['Outcome']\n",
    "\n",
    "# Step 1: Feature Importance Selection using Random Forest\n",
    "rf_initial = RandomForestClassifier(random_state=42)\n",
    "rf_initial.fit(X_full, y)\n",
    "\n",
    "feature_importances = pd.Series(rf_initial.feature_importances_, index=X_full.columns)\n",
    "selected_features = feature_importances.sort_values(ascending=False).head(10).index.tolist()\n",
    "\n",
    "print(\"=== Selected Top 10 Features by Random Forest ===\")\n",
    "print(selected_features)\n",
    "\n",
    "# Step 2: Select only top 10 features\n",
    "X = X_full[selected_features]\n",
    "\n",
    "# Step 3: Train-Test Split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Step 4: Apply SMOTE to balance training set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Random Forest with RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'min_samples_split': [4, 6, 8],\n",
    "    'min_samples_leaf': [2, 4, 6],\n",
    "    'max_features': ['sqrt', 0.5],\n",
    "    #'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_search = RandomizedSearchCV(\n",
    "    rf_model, param_distributions=param_grid,\n",
    "    n_iter=25, scoring='f1', cv=15, n_jobs=-1, random_state=42\n",
    ")\n",
    "rf_search.fit(X_train_res, y_train_res)\n",
    "best_rf = rf_search.best_estimator_\n",
    "\n",
    "# Step 6: Evaluation\n",
    "results = {}\n",
    "y_pred_train = best_rf.predict(X_train_res)\n",
    "y_pred_test = best_rf.predict(X_test)\n",
    "y_proba_train = best_rf.predict_proba(X_train_res)[:, 1]\n",
    "y_proba_test = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "for label, y_true, y_pred, y_proba in [\n",
    "    ('Train', y_train_res, y_pred_train, y_proba_train),\n",
    "    ('Test', y_test, y_pred_test, y_proba_test)\n",
    "]:\n",
    "    results[label] = {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1 Score': f1_score(y_true, y_pred),\n",
    "        'Average Recall': (recall_score(y_true, y_pred, pos_label=1) + recall_score(y_true, y_pred, pos_label=0)) / 2,\n",
    "        'AUC': roc_auc_score(y_true, y_proba),\n",
    "        'FPR_TPR': roc_curve(y_true, y_proba)\n",
    "    }\n",
    "\n",
    "# === Plotting ===\n",
    "# ROC Curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "for ax, (label, res) in zip(axes, results.items()):\n",
    "    fpr, tpr, _ = res['FPR_TPR']\n",
    "    ax.plot(fpr, tpr, label=f'{label} ROC (AUC = {res[\"AUC\"]:.2f})')\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', color='orange')\n",
    "    ax.set_title(f'{label} ROC Curve')\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "# Train\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_train_res, y_pred_train),\n",
    "                       display_labels=[\"No Diabetes\", \"Diabetes\"]).plot(ax=axes[0], cmap='Blues', values_format='d')\n",
    "axes[0].set_title('Confusion Matrix - Train')\n",
    "# Test\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_test),\n",
    "                       display_labels=[\"No Diabetes\", \"Diabetes\"]).plot(ax=axes[1], cmap='Blues', values_format='d')\n",
    "axes[1].set_title('Confusion Matrix - Test')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Print results ===\n",
    "print(\"=== Train vs Test Performance ===\")\n",
    "print(pd.DataFrame(results).T.drop(columns='FPR_TPR').round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve,\n",
    "    confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Prepare dataset (assumes df is preloaded)\n",
    "df = df.drop(columns='id', errors='ignore')\n",
    "X_full = df.drop(columns=['Outcome', 'Glucose_Bin', 'BMI_Bin', 'Age_Bin'], errors='ignore')\n",
    "y = df['Outcome']\n",
    "\n",
    "# Step 0: Feature Selection using RFE\n",
    "X_train_temp, X_test_temp, y_train_temp, y_test_temp = train_test_split(\n",
    "    X_full, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "lr_initial = LogisticRegression(random_state=42, solver='liblinear', penalty='l2')\n",
    "lr_initial.fit(X_train_temp, y_train_temp)\n",
    "\n",
    "rfe = RFE(estimator=lr_initial, n_features_to_select=10)\n",
    "rfe.fit(X_train_temp, y_train_temp)\n",
    "\n",
    "selected_features = X_full.columns[rfe.get_support()].tolist()\n",
    "print(\"=== Selected Features by RFE ===\")\n",
    "print(selected_features)\n",
    "\n",
    "X = X_full[selected_features]\n",
    "\n",
    "# Step 1: Train-test split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: SMOTE to balance training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 3: Hyperparameter tuning for Logistic Regression\n",
    "param_grid = {\n",
    "    'C': np.logspace(-4, 4, 10),\n",
    "    'penalty': ['l1','l2'],\n",
    "    'solver': ['liblinear'],\n",
    "    'max_iter': [100, 200, 300]\n",
    "}\n",
    "\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_search = RandomizedSearchCV(\n",
    "    lr_model, param_distributions=param_grid,\n",
    "    n_iter=25, scoring='f1', cv=15, n_jobs=-1, verbose=0, random_state=42\n",
    ")\n",
    "lr_search.fit(X_train_res, y_train_res)\n",
    "best_lr = lr_search.best_estimator_\n",
    "\n",
    "# Displaying the best parameters found by RandomizedSearchCV\n",
    "print(\"=== Best Hyperparameters Found ===\")\n",
    "print(lr_search.best_params_)\n",
    "\n",
    "# Step 4: Evaluation\n",
    "results = {}\n",
    "y_pred_train = best_lr.predict(X_train_res)\n",
    "y_pred_test = best_lr.predict(X_test)\n",
    "y_proba_train = best_lr.predict_proba(X_train_res)[:, 1]\n",
    "y_proba_test = best_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "for label, y_data, y_pred, y_proba in [\n",
    "    ('Train', y_train_res, y_pred_train, y_proba_train),\n",
    "    ('Test', y_test, y_pred_test, y_proba_test)\n",
    "]:\n",
    "    results[label] = {\n",
    "        'Accuracy': accuracy_score(y_data, y_pred),\n",
    "        'Precision': precision_score(y_data, y_pred),\n",
    "        'Recall': recall_score(y_data, y_pred),\n",
    "        'F1 Score': f1_score(y_data, y_pred),\n",
    "        'Average Recall': (recall_score(y_data, y_pred, pos_label=1) + recall_score(y_data, y_pred, pos_label=0)) / 2,\n",
    "        'AUC': roc_auc_score(y_data, y_proba),\n",
    "        'FPR_TPR': roc_curve(y_data, y_proba)\n",
    "    }\n",
    "\n",
    "# === Plotting ===\n",
    "# ROC Curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "for ax, (label, res) in zip(axes, results.items()):\n",
    "    fpr, tpr, _ = res['FPR_TPR']\n",
    "    ax.plot(fpr, tpr, label=f'Logistic Regression ({label} AUC = {res[\"AUC\"]:.2f})')\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', color='orange')\n",
    "    ax.set_title(f'Logistic Regression ROC Curve ({label} Set)')\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Confusion Matrices ===\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "for ax, (label, y_true, y_pred) in zip(axes, [\n",
    "    ('Train', y_train_res, y_pred_train),\n",
    "    ('Test', y_test, y_pred_test)\n",
    "]):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "    disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
    "    ax.set_title(f'Logistic Regression Confusion Matrix ({label} Set)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Results Summary ===\n",
    "results_summary = pd.DataFrame(results).T.drop(columns='FPR_TPR').round(3)\n",
    "\n",
    "print(\"=== Train vs Test Performance ===\")\n",
    "print(results_summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f546425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model with categorical features\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, precision_recall_curve,\n",
    "    confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assume df is already loaded and cleaned\n",
    "categorical_features = ['Glucose_Bin', 'BMI_Bin', 'Age_Bin']\n",
    "for cat in categorical_features:\n",
    "    df[cat] = df[cat].astype(int)\n",
    "\n",
    "# Step 0: Feature Set\n",
    "X_full = df.drop(columns=['Outcome'], errors='ignore')\n",
    "y = df['Outcome']\n",
    "\n",
    "# Step 1: Feature Importance using Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_initial = RandomForestClassifier(random_state=42)\n",
    "rf_initial.fit(X_full, y)\n",
    "\n",
    "feature_importances = pd.Series(rf_initial.feature_importances_, index=X_full.columns)\n",
    "selected_features = feature_importances.sort_values(ascending=False).head(10).index.tolist()\n",
    "print(\"=== Selected Top 10 Features by Random Forest ===\")\n",
    "print(selected_features)\n",
    "\n",
    "# Step 2: Select Top 10 Features\n",
    "X = X_full[selected_features]\n",
    "\n",
    "# Step 3: Train-Test Split (stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Step 4: SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Step 5: Logistic Regression with Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'C': np.logspace(-4, 4, 10),\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear'],\n",
    "    'max_iter': [100, 200, 300]\n",
    "}\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_search = RandomizedSearchCV(\n",
    "    lr_model, param_distributions=param_grid,\n",
    "    n_iter=25, scoring='f1', cv=15, n_jobs=-1, verbose=0, random_state=42\n",
    ")\n",
    "lr_search.fit(X_train_res, y_train_res)\n",
    "best_lr = lr_search.best_estimator_\n",
    "\n",
    "print(\"=== Best Hyperparameters Found ===\")\n",
    "print(lr_search.best_params_)\n",
    "\n",
    "# Step 6: Evaluation\n",
    "results = {}\n",
    "y_pred_train = best_lr.predict(X_train_res)\n",
    "y_pred_test = best_lr.predict(X_test)\n",
    "y_proba_train = best_lr.predict_proba(X_train_res)[:, 1]\n",
    "y_proba_test = best_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "for label, y_true, y_pred, y_proba in [\n",
    "    ('Train', y_train_res, y_pred_train, y_proba_train),\n",
    "    ('Test', y_test, y_pred_test, y_proba_test)\n",
    "]:\n",
    "    results[label] = {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1 Score': f1_score(y_true, y_pred),\n",
    "        'Average Recall': (recall_score(y_true, y_pred, pos_label=1) + recall_score(y_true, y_pred, pos_label=0)) / 2,\n",
    "        'AUC': roc_auc_score(y_true, y_proba),\n",
    "        'FPR_TPR': roc_curve(y_true, y_proba)\n",
    "    }\n",
    "\n",
    "# === Plotting ===\n",
    "# ROC Curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "for ax, (label, res) in zip(axes, results.items()):\n",
    "    fpr, tpr, _ = res['FPR_TPR']\n",
    "    ax.plot(fpr, tpr, label=f'{label} ROC (AUC = {res[\"AUC\"]:.2f})')\n",
    "    ax.plot([0, 1], [0, 1], linestyle='--', color='orange')\n",
    "    ax.set_title(f'{label} ROC Curve')\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "# Train\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_train_res, y_pred_train),\n",
    "                       display_labels=[\"No Diabetes\", \"Diabetes\"]).plot(ax=axes[0], cmap='Blues', values_format='d')\n",
    "axes[0].set_title('Confusion Matrix - Train')\n",
    "# Test\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred_test),\n",
    "                       display_labels=[\"No Diabetes\", \"Diabetes\"]).plot(ax=axes[1], cmap='Blues', values_format='d')\n",
    "axes[1].set_title('Confusion Matrix - Test')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Results Summary\n",
    "print(\"=== Train vs Test Performance ===\")\n",
    "print(pd.DataFrame(results).T.drop(columns='FPR_TPR').round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e324f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM model\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# === Step 0: Dataset Preparation ===\n",
    "df = df.drop(columns='id', errors='ignore')\n",
    "X_full = df.drop(columns=['Outcome', 'Glucose_Bin', 'BMI_Bin', 'Age_Bin'], errors='ignore')\n",
    "y = df['Outcome']\n",
    "\n",
    "# === Step 0.5: Feature Selection using Random Forest ===\n",
    "rf_initial = RandomForestClassifier(random_state=42)\n",
    "rf_initial.fit(X_full, y)\n",
    "feature_importances = pd.Series(rf_initial.feature_importances_, index=X_full.columns)\n",
    "selected_features = feature_importances.sort_values(ascending=False).head(10).index.tolist()\n",
    "\n",
    "print(\"=== Selected Top 10 Features by Random Forest ===\")\n",
    "print(selected_features)\n",
    "\n",
    "X = X_full[selected_features]\n",
    "\n",
    "# === Step 1: Train-Test Split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# === Step 2: Apply SMOTE on Training Data ===\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# === Step 3: SVM Model with RandomizedSearchCV (linear kernel) ===\n",
    "svm_model = SVC(probability=False, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.logspace(-3, 3, 10),\n",
    "    'kernel': ['linear'],\n",
    "}\n",
    "\n",
    "svm_search = RandomizedSearchCV(\n",
    "    svm_model, param_distributions=param_grid,\n",
    "    n_iter=5, scoring='f1', cv=5, n_jobs=-1, verbose=0, random_state=42\n",
    ")\n",
    "svm_search.fit(X_train_res, y_train_res)\n",
    "best_svm = svm_search.best_estimator_\n",
    "\n",
    "print(\"\\n=== Best Hyperparameters Found ===\")\n",
    "print(svm_search.best_params_)\n",
    "\n",
    "# === Step 4: Evaluation ===\n",
    "results = {}\n",
    "y_pred_train = best_svm.predict(X_train_res)\n",
    "y_pred_test = best_svm.predict(X_test)\n",
    "\n",
    "# Decision function for ROC curve\n",
    "y_score_train = best_svm.decision_function(X_train_res)\n",
    "y_score_test = best_svm.decision_function(X_test)\n",
    "\n",
    "for label, y_data, y_pred in [('Train', y_train_res, y_pred_train), ('Test', y_test, y_pred_test)]:\n",
    "    results[label] = {\n",
    "        'Accuracy': accuracy_score(y_data, y_pred),\n",
    "        'Precision': precision_score(y_data, y_pred),\n",
    "        'Recall': recall_score(y_data, y_pred),\n",
    "        'F1 Score': f1_score(y_data, y_pred),\n",
    "        'Average Recall': (recall_score(y_data, y_pred, pos_label=1) + recall_score(y_data, y_pred, pos_label=0)) / 2\n",
    "    }\n",
    "\n",
    "# === Step 5: Plotting ROC Curve (Separate Train and Test Figures) ===\n",
    "\n",
    "# ROC for Train Set\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train_res, y_score_train)\n",
    "auc_train = roc_auc_score(y_train_res, y_score_train)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_train, tpr_train, label=f'Train ROC (AUC = {auc_train:.2f})', linestyle='-', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle=':', color='black')\n",
    "plt.title('ROC Curve - Train Set (SVM Model)', fontsize=16)\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ROC for Test Set\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, y_score_test)\n",
    "auc_test = roc_auc_score(y_test, y_score_test)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_test, tpr_test, label=f'Test ROC (AUC = {auc_test:.2f})', linestyle='--', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], linestyle=':', color='black')\n",
    "plt.title('ROC Curve - Test Set (SVM Model)', fontsize=16)\n",
    "plt.xlabel('False Positive Rate', fontsize=14)\n",
    "plt.ylabel('True Positive Rate', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# === Step 6: Confusion Matrix (Train and Test) ===\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Train Confusion Matrix\n",
    "cm_train = confusion_matrix(y_train_res, y_pred_train)\n",
    "disp_train = ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=['No Diabetes', 'Diabetes'])\n",
    "disp_train.plot(ax=axes[0], cmap='Blues', values_format='d', colorbar=False)\n",
    "axes[0].set_title('Confusion Matrix - Train Set', fontsize=14)\n",
    "axes[0].grid(False)\n",
    "\n",
    "# Test Confusion Matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "disp_test = ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=['No Diabetes', 'Diabetes'])\n",
    "disp_test.plot(ax=axes[1], cmap='Blues', values_format='d', colorbar=False)\n",
    "axes[1].set_title('Confusion Matrix - Test Set', fontsize=14)\n",
    "axes[1].grid(False)\n",
    "\n",
    "plt.suptitle('SVM Model - Confusion Matrices (Train vs Test)', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# === Step 7: Results Summary ===\n",
    "results_summary = pd.DataFrame(results).T.round(3)\n",
    "\n",
    "print(\"\\n=== Train vs Test Performance Summary ===\")\n",
    "print(results_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
